# 1. SRIOV Introduction
http://www.sdnlab.com/14403.html
     
PCI-SIG 组织发布了 SR-IOV（Single Root I/O Virtualization and Sharing）规范，该规范定义了一个标准化的机制用以原生地实现多个共享的设备（不一定是网卡设备）。QEMU/KVM在2009年实现了对SR-IOV技术的支持，其他一些虚拟化方案也都支持 SR-IOV 了。

![](/kvm_blog/files/virt_io/sriov1.png)

![](/kvm_blog/files/virt_io/sriov2.png)
 
SR-IOV 中的两种新功能类型是：

- 物理功能 (Physical Function, PF)，用于支持 SR-IOV 功能的 PCI 功能，如 SR-IOV 规范中定义。PF 包含 SR-IOV 功能结构，用于管理 SR-IOV 功能。PF 是全功能的 PCIe 功能，可以像其他任何 PCIe 设备一样进行发现、管理和处理。PF 拥有完全配置资源，可以用于配置或控制 PCIe 设备。

- 虚拟功能 (Virtual Function, VF)，与物理功能关联的一种功能。VF 是一种轻量级 PCIe 功能，可以与物理功能以及与同一物理功能关联的其他 VF 共享一个或多个物理资源。VF 仅允许拥有用于其自身行为的配置资源。

每个 SR-IOV 设备都可有一个物理功能 (Physical Function, PF)，并且每个 PF 最多可有 64,000 个与其关联的虚拟功能 (Virtual Function, VF)。PF 可以通过寄存器创建 VF，这些寄存器设计有专用于此目的的属性。

一旦在 PF 中启用了 SR-IOV，就可以通过 PF 的总线、设备和功能编号（路由 ID）访问各个 VF 的 PCI 配置空间。每个 VF 都具有一个 PCI 内存空间，用于映射其寄存器集。VF 设备驱动程序对寄存器集进行操作以启用其功能，并且显示为实际存在的 PCI 设备。创建 VF 后，可以直接将其指定给 IO 来宾域或各个应用程序（如裸机平台上的 Oracle Solaris Zones）。此功能使得虚拟功能可以共享物理设备，并在没有 CPU 和虚拟机管理程序软件开销的情况下执行 I/O。

SR-IOV 为客户机中使用的VF提供了独立的内存空间、中断、DMA流，从而不需要 Hypervisor 介入数据的传送过程。SR-IOV 架构设计的目的是允许一个设备支持多个VF，同时也尽量减少每个VF的硬件成本。


# 2. Configure NIC #
## 2.1 Check if PCI support SR-IOV ##

    lspci -v -s $bdf | grep SR-IOV

## 2.2 Load Driver ##

    modprobe -r ixgbe
    modprobe ixgbe max_vf=3    // 最大 VF 数
 
SRIOV INFO

	modinfo igb
	modinfo igbxe**
  

## 2.3 Create VF ##
	
	ifconfig eth11
	echo 2 > /sys/class/net/eth11/device/sriov_numvfs
	lspci | grep Eth
	ls -l /sys/bus/pci/devices/0000\:01\:00.0/virtfn*

## 2.4 Check VF Info

	[root@knl2 ns]# ls -l /sys/bus/pci/devices/0000:01:00.1/

    ls -l /sys/bus/pci/devices/0000\:0d\:00.0/virtfn*
    ls -l /sys/bus/pci/devices/0000\:0e\:10.0/physfn

## 1.4 Other ##

	ip link show
	ethtools -i eth1
	lspci | grep Eth



# 3. SR-IOV Problem #

## 3.1 P1: VF 在客户机中MAC地址全为 0

如果使用 Linux 3.9 及之后的版本作为宿主机的内核，则可能会在使用 igb 或 ixgbe驱动的网卡的VF进行SR-IOV时，在客户机中看到 igbvf 或 ixgbevf网卡的MAC地址全为0。你可以在 dmesg 看到 00:00:00:00:00:00。
    
方法一：手动设置下 MAC地址就可以解决

    ip link set eth0 vf 0 mac 00:1E:67:65:93:01
    上面的命令中， eth0 为宿主机中PF对应的以太网接口名称，0代表设置的VF是该PF的编号为0的VF（第一个VF）

那么如何确定这个VF编号对应的PCI-E设备的BDF编号呢？可以用如下命令查看：
    
	ethtool -i eth0 查出BDF
    ls -l /sys/bus/pci/devices/0000\:0d\:00.0/virtfn*
 
方法二：可以升级客户机系统的内核或VF驱动程序
      
比如可以将 Linux 客户机升级到使用 Linux 3.9之后的内核及其对应的 igbvf驱动程序。最新的 igbvf 驱动程序可以处理 VF 的 MAC 地址为零的情况。


## 3.2 P2: Windows haven't VF Driver ##

解决方法，去官网下载相应的驱动装上即可。例如前面提及的 Intel 网卡驱动可以到其官方网站下载：https://downloadcenter.intel.com/
    
## 3.3 P3: Windows Guest Can't Use VF ##

**问题描述**：     
      
在默认的 qemu-kvm命令行启动客户机后，Intel 82576、82579网卡的VF在32 位 Windows Server 2008 版的客户机中不能正常工作，而在 64位客户机中的工作正常。

**问题原因**：

默认的 CPU模型是 qemu64，它不支持 MSI-X这种中断方式，而32位的 Windows Server 2008 版本中 82576、82599网卡的VF只能用 MSI-X这种中断方式来工作。所以，需要在通过命令行启动客户机时指定 QEMU 模拟的CPU的类型，从而可以绕过这个问题。可以用“-cpu SandyBridge"等参数来指定CPU的默认类型。

    qemu-system-x86_64 32bit-win2k8.img -smp 2 -cpu SandyBridge -m 1024 -device pci-assign,host=$bdf -net none
